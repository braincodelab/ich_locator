{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ich_locator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "from utils import convert, extract, registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \n",
    "table_path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = '/home/'\n",
    "\n",
    "os.chdir(data_path)\n",
    "files = sorted(os.listdir('.'))\n",
    "\n",
    "os.chdir(data_path)\n",
    "files = sorted(next(os.walk(data_path))[2])\n",
    "\n",
    "images = [f for f in files if '.nii.gz' in f]\n",
    "  \n",
    "names = sorted(list(set([f[:7] for f in images])))\n",
    "\n",
    "image_set = []\n",
    "\n",
    "for name in names:\n",
    "    subject_images = [f for f in images if f[:7] == name]\n",
    "    image = subject_images[0]\n",
    "    image_set.append(image)\n",
    "\n",
    "            \n",
    "images = image_set\n",
    "\n",
    "df = pd.DataFrame(columns = ['subject', 'deep', 'lobar', 'infra']) \n",
    "\n",
    "df['subject'] = names\n",
    "\n",
    "df.head(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the excel files, search for the cell for each name with lobar etc. and put in the new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  #if isinstance(value, type(tf.constant(0))):\n",
    "  #      value = value.numpy()\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# Create the serialized example of features\n",
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \n",
    "    feature = {'deep': _int64_feature(feature0),\n",
    "               'lobar': _int64_feature(feature1),\n",
    "               'infra': _int64_feature(feature2),\n",
    "               'image': _bytes_feature(tf.compat.as_bytes(feature3))}\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = nib.load('/home/datasets/tfrecords_conversion_old/templates/scct_unsmooth_SS_0.01_128x128x128.nii.gz')\n",
    "template = convert.nii2ants(template)\n",
    "\n",
    "def tfrecords_conversion(filename, data_path, images):\n",
    "    \n",
    "    # Open the writer \n",
    "    writer = tf.io.TFRecordWriter(filename)\n",
    "    \n",
    "    # Iterate over files\n",
    "    for i in range(len(images)): \n",
    "\n",
    "        image = nib.load(os.path.join(data_path,images[i]))\n",
    "        image = convert.nii2ants(image)\n",
    "        image, transforms = registration.rigid(template, image)\n",
    "        image = image.numpy() #look at ants docs\n",
    "        \n",
    "        print(np.amin(image), np.amax(image))\n",
    "        \n",
    "        #find the values for each subject here to serialize\n",
    "        lobar_val = df.loc(subject==).value()\n",
    "        deep_val = df.loc\n",
    "        infra_val = df.loc\n",
    "        \n",
    "        example = serialize_example(deep_val, lobar_val, infra_val, image.tostring())\n",
    "    \n",
    "        # Serialize to string and write to file\n",
    "        writer.write(example)\n",
    "        sys.stdout.flush()  # to read any intermediate error messages\n",
    "\n",
    "    writer.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords_conversion(filename, data_path, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        shape = image.shape\n",
    "        new_shape = (128, 128, 128)\n",
    "        image = image.astype(np.float32)\n",
    "        image =  scipy.ndimage.zoom(image, (new_shape[0]/shape[0], new_shape[1]/shape[1], new_shape[2]/shape[2]), order=0)\n",
    "        print(image.shape)\n",
    "        \n",
    "        if image.shape != new_shape:\n",
    "            print(\"FAIL\", image.shape, images[i])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
